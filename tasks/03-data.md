# Data

## Data Acquisition and Analysis

Write scripts in your favourite language to perform the following tasks:

1. Process Wiktionary dump to extract synonym relations for a random language (not English, Ukrainian or Russian :) - requires application of XML SAX parsing

2. Download and extract as separate texts all posts in an section of choice from <http://forum.lvivport.com> - requires web-scraping

3. Write a query to collect all relations from dbpedia for every individual person listed in it - requires running a SPARQL request at <https://dbpedia.org/sparql>

4. Download and process an arbitrary file from Common Crawl (<https://index.commoncrawl.org/>), extract individual items, perform basic statistical analysis (distribution of hosts, words, languages, domains etc.) and visualization (optional)

## Annotation

1. According to the [annotation guidelines](https://github.com/lang-uk/ner-uk/blob/master/doc/README.md), annotate 2 documents from the BrUK corpus for NERs for your username at <http://ann.lisp.kiev.ua/>.

2. Process data from the [NUCLE Error Corpus](http://www.comp.nus.edu.sg/~nlp/conll14st.html#nucle32) and analyze inter-annotator agreement in it (general and for each error type).

## Project

1. Perform initial data collection for your project.
2. Devise and describe a way to collect data for your course project using crowdsourcing or from the users. Implement a proof-of-concept.


## Grading

Acquisition: 60%

- task1: 15%
- task2: 15%
- task3: 10%
- task4: 20%

Annotation: 30%

- task1: 10%
- task2: 20%

Project: 10%

## Deadline

23.03.2019
