{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from tokenize_uk.tokenize_uk import tokenize_words\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows count: 14949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>item_bought</th>\n",
       "      <th>review</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>downvotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23415273</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>сервіс відмінний, морозильна камера працює добре.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33284346</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>гарна та якісна морозильна камера. при першому...</td>\n",
       "      <td>недорогий</td>\n",
       "      <td>нема</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33040878</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>камеру привезли, все працює, все добре, все як...</td>\n",
       "      <td></td>\n",
       "      <td>немає</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38902893</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>справляється із своєю роботою</td>\n",
       "      <td>ціна якість</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20357268</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>користуюсь міс., дуже задоволений!</td>\n",
       "      <td>все чудово працює, тихий.</td>\n",
       "      <td>поки не виявлено.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating  item_bought  \\\n",
       "id                              \n",
       "23415273       5            1   \n",
       "33284346       5            1   \n",
       "33040878       4            1   \n",
       "38902893       5            1   \n",
       "20357268       5            1   \n",
       "\n",
       "                                                     review  \\\n",
       "id                                                            \n",
       "23415273  сервіс відмінний, морозильна камера працює добре.   \n",
       "33284346  гарна та якісна морозильна камера. при першому...   \n",
       "33040878  камеру привезли, все працює, все добре, все як...   \n",
       "38902893                      справляється із своєю роботою   \n",
       "20357268                 користуюсь міс., дуже задоволений!   \n",
       "\n",
       "                               pros               cons  upvotes  downvotes  \n",
       "id                                                                          \n",
       "23415273                                                      0          0  \n",
       "33284346                  недорогий               нема        0          0  \n",
       "33040878                                         немає        2          0  \n",
       "38902893                ціна якість                           0          0  \n",
       "20357268  все чудово працює, тихий.  поки не виявлено.        0          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/input/comments.tsv', sep='\\t', index_col=0)\n",
    "df_tones = pd.read_csv('data/input/tone-dict-uk.tsv', sep='\\t', index_col=0, names=['tone'])\n",
    "df = df.fillna('')\n",
    "print('rows count:', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set([\"а\",\"або\",\"але\",\"б\",\"без\",\"би\",\"бо\",\"був\",\"буде\",\"була\",\"були\",\"було\",\"бути\",\"в\",\"вам\",\"вами\",\"вас\",\"ваш\",\"ваша\",\"ваше\",\"вашим\",\"вашими\",\"ваших\",\"ваші\",\"вашій\",\"вашого\",\"вашої\",\"вашому\",\"вашою\",\"вашу\",\"вже\",\"ви\",\"від\",\"він\",\"вона\",\"вони\",\"воно\",\"всі\",\"де\",\"для\",\"до\",\"дуже\",\"є\",\"з\",\"за\",\"зі\",\"і\",\"із\",\"її\",\"їй\",\"їм\",\"їх\",\"й\",\"його\",\"йому\",\"ким\",\"кого\",\"коли\",\"кому\",\"лише\",\"має\",\"мене\",\"мені\",\"ми\",\"мій\",\"мною\",\"мого\",\"моє\",\"моєї\",\"моєму\",\"моєю\",\"можна\",\"мої\",\"моїй\",\"моїм\",\"моїми\",\"моїх\",\"мою\",\"моя\",\"на\",\"нам\",\"нами\",\"нас\",\"наш\",\"наша\",\"наше\",\"нашим\",\"нашими\",\"наших\",\"наші\",\"нашій\",\"нашого\",\"нашої\",\"нашому\",\"нашою\",\"нашу\",\"неї\",\"нею\",\"ним\",\"ними\",\"них\",\"ній\",\"нім\",\"ну\",\"нього\",\"ньому\",\"під\",\"після\",\"по\",\"при\",\"про\",\"саме\",\"себе\",\"собі\",\"та\",\"так\",\"також\",\"там\",\"твій\",\"твого\",\"твоє\",\"твоєї\",\"твоєму\",\"твоєю\",\"твої\",\"твоїй\",\"твоїм\",\"твоїми\",\"твоїх\",\"твою\",\"твоя\",\"те\",\"тебе\",\"ти\",\"тим\",\"тими\",\"тих\",\"ті\",\"тієї\",\"тією\",\"тій\",\"тільки\",\"тім\",\"то\",\"тобі\",\"тобою\",\"того\",\"тоді\",\"той\",\"тому\",\"ту\",\"тут\",\"у\",\"хто\",\"це\",\"цей\",\"ці\",\"цього\",\"цьому\",\"через\",\"чи\",\"чиє\",\"чиєї\",\"чиєму\",\"чиї\",\"чиїй\",\"чиїм\",\"чиїми\",\"чиїх\",\"чий\",\"чийого\",\"чийому\",\"чим\",\"чию\",\"чия\",\"чого\",\"чому\",\"що\",\"щоб\",\"щодо\",\"щось\",\"я\",\"як\",\"яка\",\"який\",\"які\",\"якщо\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "def tokenizer(string):\n",
    "    return [morph.parse(word)[0].normal_form for word in tokenize_words(string) if word and word not in stopwords]\n",
    "\n",
    "def sentiment_tokenizer(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if token:\n",
    "            if token in df_tones.index:\n",
    "                result.append(df_tones.at[token, 'tone'])\n",
    "            else:\n",
    "                result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='word')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='word')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss = 'hinge', penalty = 'l2', \n",
    "                          alpha = 1e-4, random_state = 1,\n",
    "                          max_iter = 50, tol = None)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6224662162162162"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_tones = df.copy()\n",
    "df_with_tones['review_tones'] = df_with_tones['review'].apply(tokenizer).apply(sentiment_tokenizer).str.join('_rev ')\n",
    "df_with_tones = df_with_tones.dropna(subset=['review_tones'])\n",
    "x_train_tones, x_test_tones, y_train_tones, y_test_tones = train_test_split(df_with_tones['review_tones'], df_with_tones['rating'], test_size=0.3, random_state=1)\n",
    "\n",
    "text_clf.fit(x_train_tones, y_train_tones)\n",
    "predicted = text_clf.predict(x_test_tones)\n",
    "np.mean(predicted == y_test_tones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5962837837837838"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(x_train_tones, y_train_tones)\n",
    "predicted = svm_clf.predict(x_test_tones)\n",
    "np.mean(predicted == y_test_tones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['review'].apply(tokenizer).str.join('_rev ')\n",
    "x_train, x_test, y_train, y_test = train_test_split(reviews, df['rating'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6831661092530658"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(x_train, y_train)\n",
    "predicted = text_clf.predict(x_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7076923076923077"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(x_train, y_train)\n",
    "predicted = svm_clf.predict(x_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding pros and cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725752508361204"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pros = df['pros'].apply(tokenizer).str.join('_pros ')\n",
    "cons = df['cons'].apply(tokenizer).str.join('_cons ')\n",
    "with_adv = reviews.str.cat([pros, cons], sep=' ')\n",
    "\n",
    "x_train_adv, x_test_adv, y_train_adv, y_test_adv = train_test_split(with_adv, df['rating'], test_size=0.3, random_state=1)\n",
    "\n",
    "svm_clf.fit(x_train_adv, y_train_adv)\n",
    "predicted_adv = svm_clf.predict(x_test_adv)\n",
    "np.mean(predicted_adv == y_test_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7261984392419175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upvotes = df['upvotes'].astype(str) + '_upv'\n",
    "downvotes = df['downvotes'].astype(str) + '_down'\n",
    "\n",
    "with_votes = with_adv.str.cat([upvotes, downvotes], ' ')\n",
    "\n",
    "x_train_votes, x_test_votes, y_train_votes, y_test_votes = train_test_split(with_votes, df['rating'], test_size=0.3, random_state=1)\n",
    "\n",
    "svm_clf.fit(x_train_votes, y_train_votes)\n",
    "predicted_votes = svm_clf.predict(x_test_votes)\n",
    "np.mean(predicted_votes == y_test_votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### considering whether the item was bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7264214046822742"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_bought = df['item_bought'].astype(str) + '_bought'\n",
    "with_bought = with_adv.str.cat(item_bought, sep=' ')\n",
    "\n",
    "x_train_bought, x_test_bought, y_train_bought, y_test_bought = train_test_split(with_bought, df['rating'], test_size=0.3, random_state=1)\n",
    "\n",
    "svm_clf.fit(x_train_bought, y_train_bought)\n",
    "predicted_bought = svm_clf.predict(x_test_bought)\n",
    "np.mean(predicted_bought == y_test_bought)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
